# Benchmarking-for-Drug-Discovery-Datasets

# Data Quality Checkpoints

Welcome to the **Data Quality Checkpoints** repository! This project is your go-to resource for maintaining high data quality in your datasets. It provides a comprehensive suite of tools for identifying duplicates, analyzing property distributions, visualizing data, and checking for structural issues like stereochemistry and invalid charges. As this repository is under active development, we kindly ask for your patience and welcome any contributions to help improve and evolve the toolkit.

## Features

- **Identifying Duplicates**: Tools to detect and handle duplicate records in your datasets.
- **Understanding Property Distribution**: Analyze and understand the distribution of properties within your datasets for better data management.
- **Plotting and Visualization**: Utilities for creating insightful visualizations to explore your data further.
- **Checking Structural Issues**: Validate the integrity of your data by checking for stereochemistry issues, invalid charges, and more.
- **Actively Evolving**: This repository is a work in progress. New features and improvements will be added continually.

## Getting Started

To make the most out of the Data Quality Checkpoints, follow these steps:

### 1. Clone the Repository

Clone this repository to your local machine to get started:

```bash
git clone https://github.com/<your-github-username>/data-quality-checkpoints.git

ðŸš§ Project Status: Getting Ready for Launch! ðŸš§

We are excited to announce that this GitHub repository is swiftly moving towards its launch! Currently, it's a hive of activity as we lay the groundwork for something truly special.

What to Expect:

Work in Progress: Our team is diligently preparing the repository, ensuring that everything is set for a smooth launch.
Coming Soon: Stay tuned for the deployment of our initial version. We're just as eager as you are to share our work with the community.
New Features and Improvements: Beyond the initial release, we have a roadmap packed with new features, enhancements, and updates. Our commitment is to continuously evolve and adapt, providing you with tools that meet and exceed your expectations.
Stay Updated: Keep an eye on this space! We'll share progress updates, sneak peeks, and launch announcements. Your feedback and suggestions are always welcome as they are invaluable in shaping the future of this project.

Thank you for your patience and support. We can't wait to unveil what we've been working on!
..........................
## 2. Install Dependencies. 

Navigate to the repository directory and install the required dependencies:

```bash
pip install -r requirements.txt
```

## 3. Utilize the Tools

Execute the scripts to perform various data quality checks. For example, to identify duplicate records in your dataset:

```bash
python identify_duplicates.py
```

For specific instructions on each tool, refer to the individual script documentation.

## Contributing

We welcome contributions from the community! If you have suggestions for new features, improvements, or have found a bug, please feel free to open an issue or submit a pull request.

## Disclaimer

Please note that this project is in active development. The features and documentation are subject to change as we refine and expand our toolkit.

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.

## Contact

For any questions or feedback, please contact us at suneelkumar.bvs@gmail.com.

Thank you for visiting the Data Quality Checkpoints repository!
